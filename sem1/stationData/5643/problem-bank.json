{
  "problemBankGridLines": null,
  "projectGridLines": [
    {
      "stationId": 5643,
      "stationName": "American Express - AiDa, Bengaluru",
      "stationCity": null,
      "businessDomain": "CSIS/IT",
      "problemBankId": 1045,
      "projectId": 1870,
      "semesterId": 1,
      "pstypeId": 2,
      "psType": "PS II",
      "batchId": 16,
      "batch": "2024-25",
      "title": "Optimizing Amex boosting algorithm",
      "description": "<p class=\"ql-align-justify\"><strong style=\"color: black;\">Description and Outcome</strong><span style=\"color: black;\">: Gradient Boosting Machine (GBM) is one of the widely used technique in Financial Services organization specifically for Fraud and Credit usecases. Amex has its custom version of boosting machine algorithm for similar usecases. This boosting machine algorithm is hosted on Big Data infrastructure and data scientists leverage it through the enterprise ML platform for their model development. The algorithm is only executable in a standalone machine, and this impacts the capabilities of the algorithm and its runtime. </span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">In the project, candidate (intern) will be working towards identification of approaches to distribute the model build execution. The intern will be expected to quickly pick up boosting algorithms, distributed computing and try out different methods to optimize the execution of the tree building process. The project will also be extended to replicate the solution on a GPU environment to further, improve the execution efficiency of the algorithm.</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">Skill sets</strong><span style=\"color: black;\">: Python, Java, Understanding of Unix, Gradient Boosting Algorithms such as XGBoost, Data Structures.</span></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">&nbsp;</strong></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">Expected learning</strong><span style=\"color: black;\">: Understanding of Amex Boosting algorithm, Big Data Environment and execution mechanism for a distributed job. Principles of optimizing the Big Data Jobs.</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">Specific courses required for project execution: Programming in Python, Linux / Unix understanding, Big Data framework such as Spark, Algorithms, classical ML algorithms such as XGBoost in addition to Linear Regression, SVMs, other classification / regression methods.</span></p><p><br></p>",
      "projectDomain": "",
      "projectSubDomain": null,
      "ugStipend": 125000,
      "pgStipend": 0,
      "totalMaleRequirement": 0,
      "totalFemalRequirement": 0,
      "totalRequirment": 0,
      "discipline": "",
      "sumOfStipend": 125000,
      "createdBy": "planning@bits.com",
      "assignedFacultyEmailId": null,
      "studentProjectDetails": null
    },
    {
      "stationId": 5643,
      "stationName": "American Express - AiDa, Bengaluru",
      "stationCity": null,
      "businessDomain": "CSIS/IT",
      "problemBankId": 1045,
      "projectId": 1872,
      "semesterId": 1,
      "pstypeId": 2,
      "psType": "PS II",
      "batchId": 16,
      "batch": "2024-25",
      "title": "Amex on premise Big Data Cluster monitoring and Analysis System",
      "description": "<p class=\"ql-align-justify\"><strong style=\"color: black;\">Description and Outcome: </strong><span style=\"color: black;\">Financial institutions typically leverage Big Data frameworks to run their heavy data processing and machine learning applications for their business usecases. These frameworks require large compute to cater to Service Level Objectives (SLOs). </span></p><p class=\"ql-align-justify\"> In a shared infrastructure setup, computing resources are shared between different Line of Businesses (LOBs) that leads to various challenges, the primary one being resource starvation another challenge is disk utilization reaching its peak values leading to failure of jobs and wastage of disk resources. </p><p class=\"ql-align-justify\"> </p><p class=\"ql-align-justify\"> </p><p class=\"ql-align-justify\"><span style=\"color: black;\">As a data scientist / analytical user, this impacts their productivity. A Product / Platform owner has no prior way to predict about occurrences of such problems. Hence will have to provide adhoc, manual support to users.</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">The project aims at contributing towards the Amex ML Platform Hardening initiative.</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\"> The objective is to develop a capability to proactively track and monitor the overall cluster, disk utilization, queues, and its resources part of Amex Big Data infrastructure at a job and user level. Generate aggregations at the different levels like job type, user, team, time-period etc. and trigger notifications / alerts basis the results of aggregations. Further, the insights (output) from the capability must be leveraged to validate whether the policies (guidelines) outlined in rationalization are followed by end users.</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">Skill sets</strong><span style=\"color: black;\">: Python, Linux / Unix understanding, Big Data fundamentals such as Hadoop, Spark, Algorithms, Data Structures.</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">Expected learning</strong><span style=\"color: black;\">: Big Data framework for Analytical and AI / ML workloads in shared infrastructure, general recommendations for users based on jobs / workloads executed.</span></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">&nbsp;</strong></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">Specific courses required for project execution</strong><span style=\"color: black;\">:&nbsp;Programming in Python, Linux / Unix understanding, Data structures. Acquaintance with Big Data environments will be an added advantage, visualizing big data platform logs using Splunk / Kibana will be a plus.</span></p><p><br></p>",
      "projectDomain": "",
      "projectSubDomain": null,
      "ugStipend": 125000,
      "pgStipend": 0,
      "totalMaleRequirement": 0,
      "totalFemalRequirement": 0,
      "totalRequirment": 0,
      "discipline": "",
      "sumOfStipend": 125000,
      "createdBy": "planning@bits.com",
      "assignedFacultyEmailId": null,
      "studentProjectDetails": null
    },
    {
      "stationId": 5643,
      "stationName": "American Express - AiDa, Bengaluru",
      "stationCity": null,
      "businessDomain": "CSIS/IT",
      "problemBankId": 1045,
      "projectId": 1873,
      "semesterId": 1,
      "pstypeId": 2,
      "psType": "PS II",
      "batchId": 16,
      "batch": "2024-25",
      "title": "Enterprise ML Platform Workload Monitoring on Dataproc cluster & Cost Optimization Insights ",
      "description": "<p class=\"ql-align-justify\"><strong style=\"color: black;\">Description:&nbsp;</strong><span style=\"color: black;\">Enterprise is moving towards GCP as its point of arrival. We are gradually onboarding users along with relevant ML capabilities on them. We are working closely with the Google Cloud Platform team to enable dashboard for our workloads which would give insights into the resource (CPU/GPU) utilization and various other services being leveraged in the cluster. We also have a logging a framework that captures the cluster life cycle in terms start, end time, the workload it ran &amp; cost it incurred.</span></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">&nbsp;</strong></p><p class=\"ql-align-justify\"><span style=\"color: black;\">The candidate would work toward developing a utility that generated insights (summary) which are easily interpretable and correlate the resource utilization KPIs to cost using statistical analysis techniques. The tool should be able to give a health report for a specific cluster resource by analyzing different KPIs and its effect on cost. Possibly detect its deviation from ideal behavior and come up with a scoring mechanism for the same. </span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">A stretch goal would be to predict cost and ideal resource utilization behavior from workload details.</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">Skill sets</strong><span style=\"color: black;\">: Python, Linux / Unix understanding, Big Data fundamentals such as Hadoop, Spark, Algorithms, GCP platform fundamentals would be added plus. Understanding of Boosting algorithm, HPT, AI / ML GPU compatibility aspects would be a plus. </span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><strong style=\"color: black;\">Expected learning</strong><span style=\"color: black;\">: Big Data framework for Analytical and AI / ML workloads on public cloud, dask&amp; rapids framework support for compute intensive tasks ,&nbsp;general recommendations for users based on jobs / workloads executed by different modelling teams in Amex. </span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">&nbsp;</span></p><p class=\"ql-align-justify\"><span style=\"color: black;\">Specific courses required for project execution:&nbsp;Programming in Python, Linux / Unix understanding, Data structures. Acquaintance with Big Data environments will be an added advantage, visualizing big data platform logs using Splunk / Kibana will be a plus.</span></p><p><br></p>",
      "projectDomain": "",
      "projectSubDomain": null,
      "ugStipend": 125000,
      "pgStipend": 0,
      "totalMaleRequirement": 0,
      "totalFemalRequirement": 0,
      "totalRequirment": 0,
      "discipline": "",
      "sumOfStipend": 125000,
      "createdBy": "planning@bits.com",
      "assignedFacultyEmailId": null,
      "studentProjectDetails": null
    }
  ]
}